{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Artificial network generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "sys.path.insert(0, \"./scripts\")\n",
    "import functions as f\n",
    "from copy import deepcopy\n",
    "import networkx as nx\n",
    "from collections import namedtuple\n",
    "from itertools import product, combinations\n",
    "from matplotlib import pyplot as plt\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "from time import sleep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RANDOM_SEED: 19\n",
      "TEST_NETWORK_SIZE: 500\n",
      "TEST_NETWORK_LINK_PROB: 0.1\n",
      "N_CORES_TO_USE: -1\n",
      "NETWORK_TO_SEARCH_IN: yeast\n"
     ]
    }
   ],
   "source": [
    "cfg = f.get_actual_parametrization(\"./config.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Yeast Tnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RANDOM_SEED: 19\n",
      "TEST_NETWORK_SIZE: 500\n",
      "TEST_NETWORK_LINK_PROB: 0.1\n",
      "N_CORES_TO_USE: -1\n",
      "NETWORK_TO_SEARCH_IN: yeast\n"
     ]
    }
   ],
   "source": [
    "cfg = f.update_cfg(\"./config.json\", \"NETWORK_TO_SEARCH_IN\", \"yeast\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "interaction_matrix = f.get_interaction_matrix(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.51 s, sys: 142 ms, total: 2.66 s\n",
      "Wall time: 7.81 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'021C': 37631, '021D': 1059856, '021U': 26042, '030C': 8, '030T': 3370}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "motifs_orig, counter_orig = f.motif_search(cfg, interaction_matrix, batch_size=10000)\n",
    "counter_orig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vertex-based motif network on FFL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "motifs = motifs_orig[\"030T\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5676765/5676765 [00:15<00:00, 362315.08it/s]\n"
     ]
    }
   ],
   "source": [
    "motifs_network = f.build_vmn(motifs, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "V = nx.Graph(motifs_network)\n",
    "nx.is_connected(V)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generation algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Nucleation\n",
    "One needs a piece of the real network to get reasonable probability estimates for further preferential attachment workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_network_nucleus(\n",
    "    interaction_matrix, motifs, motifs_network, min_size, random_seed=cfg[\"RANDOM_SEED\"]\n",
    "):\n",
    "    \"\"\"\n",
    "    Getting subsample from real network as a nucleus for artificial network\n",
    "    ________________________________________________________________________\n",
    "    interaction_matrix (numpy.array) - binary interaction matrix for genes\n",
    "    motifs (numpy.array) - list of unique identifiers for condidered motifs (FFL triads)\n",
    "    motifs_network (numpy.array) - vertex-based motifs network (linkage by shared nodes)\n",
    "    min_size (int) - minimal required size of resulting nucleus (may be slightly higher eventually)\n",
    "    random_seed (int) - reproducibility parameter\n",
    "    \n",
    "    \"\"\"\n",
    "    np.random.seed(random_seed)\n",
    "    substrate_motif_idxs = [np.random.randint(len(motifs))]\n",
    "    substrate_motifs = np.array([motifs[i] for i in substrate_motif_idxs])\n",
    "    substrate_size = len(set(sum([f.split_motif(motif) for motif in substrate_motifs], [])))\n",
    "\n",
    "    # grow network nucleus while required size obtained\n",
    "    while substrate_size < min_size:\n",
    "        neighbors = np.where(motifs_network[:, substrate_motif_idxs].sum(axis=1) != 0)[0]\n",
    "        neighbors = np.array(list(set(neighbors) - set(substrate_motif_idxs)))\n",
    "        # assignment of weights to candidate motifs by their connectivity\n",
    "        # with already selected motifs grown substrate network\n",
    "        weights = motifs_network[neighbors, :][:, substrate_motif_idxs].sum(axis=1)\n",
    "        weights /= sum(weights)\n",
    "        substrate_motif_idxs.append(np.random.choice(neighbors, size=1, p=weights)[0])\n",
    "        substrate_motifs = np.array([motifs[i] for i in substrate_motif_idxs])\n",
    "        substrate_size = len(set(sum([f.split_motif(motif) for motif in substrate_motifs], [])))\n",
    "\n",
    "    # interaction matrix building\n",
    "    G = nx.DiGraph()\n",
    "    for motif in substrate_motifs:\n",
    "        nodes = f.split_motif(motif)\n",
    "        M = nx.DiGraph(interaction_matrix[nodes, :][:, nodes])\n",
    "        M = nx.relabel_nodes(M, mapping={i: node for i, node in enumerate(nodes)})\n",
    "        G = nx.compose(G, M)\n",
    "    substrate_matrix = nx.convert_matrix.to_numpy_array(G)\n",
    "    return substrate_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parametrization\n",
    "Motif types and number of shared nodes distributions inference. \n",
    "\n",
    "The support set for FFL motif type by TF/TG content is {TTT, TTG} where T and G are for TF and TG respectively.\n",
    "\n",
    "The support set for the number of shared nodes is {1, 2}. We are not considering 0 as we focus only on the largest connected component of FFL VMN which actually contains all of the FFLs in the yeast Tnet and nearly all (99%) in E.coli Tnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_network_params(substrate_matrix):\n",
    "    \"\"\"\n",
    "    Inference of preferencial attachment algorithm parameters from current substrate network\n",
    "    ________________________________________________________________________\n",
    "    substrate_matrix - the netwotk we are growing\n",
    "    \"\"\"\n",
    "    motifs_substr, counter_substr = f.motif_search(\n",
    "        cfg, substrate_matrix, batch_size=10000, verbose=False\n",
    "    ) # motif counting\n",
    "    substrate_motifs = motifs_substr[\"030T\"]\n",
    "    # TF/TG recognition\n",
    "    tf_nodes = np.where(substrate_matrix.sum(axis=0) != 0)[0]\n",
    "    tg_nodes = np.where(substrate_matrix.sum(axis=0) == 0)[0]\n",
    "    # motif type distribution\n",
    "    n_tg_nodes_list = np.array(\n",
    "        [len(set(f.split_motif(motif)) - set(tf_nodes)) for motif in substrate_motifs]\n",
    "    )\n",
    "    mtype_probs = pd.Series(n_tg_nodes_list).value_counts(normalize=True).sort_index()\n",
    "    # shared nodes number distribution\n",
    "    substrate_vmn = f.build_vmn(substrate_motifs)\n",
    "    shared_nodes_probs = pd.Series(\n",
    "        [x for x in substrate_vmn.flatten() if x != 0]\n",
    "    ).value_counts(normalize=True)\n",
    "    # results packing\n",
    "    Params = namedtuple(\n",
    "        \"Params\", \"substrate_motifs substrate_vmn tf_nodes tg_nodes mtype_probs shared_nodes_probs\"\n",
    "    )\n",
    "    params = Params(\n",
    "        *[substrate_motifs, substrate_vmn, tf_nodes, tg_nodes, mtype_probs, shared_nodes_probs]\n",
    "    )\n",
    "    return params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Single attachment step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random selection of the inner/outer motif types and number of shared nodes with probabilities from the previous step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_attachment_params(params):\n",
    "    \"\"\"\n",
    "    Selection of inner/outer motifs and number of shared nodes\n",
    "    ________________________________________________________________________\n",
    "    params - network parameters from previous stage of analysis (see get_network_params)\n",
    "    \"\"\"\n",
    "    # substrate motif type selection\n",
    "    intype = np.random.choice(params.mtype_probs.index, p=params.mtype_probs.values)\n",
    "    substrate_type_idxs = np.where(\n",
    "        np.array([len(set(f.split_motif(x)) - set(params.tf_nodes)) for x in params.substrate_motifs]) == intype\n",
    "    )[0]\n",
    "    # buiding VMN for motifs of chosen type\n",
    "    substrate_type_vmn = params.substrate_vmn[substrate_type_idxs, :][:, substrate_type_idxs]\n",
    "    type_V = nx.Graph(substrate_type_vmn)\n",
    "    # weights assignment for chosen motifs by their degree centrality\n",
    "    weights = np.array([substrate_type_vmn[i, :].sum() for i in range(len(substrate_type_idxs))])\n",
    "    weights /= sum(weights)\n",
    "    # weighted random selection of particular substrate network node\n",
    "    inner_motif_idx = np.random.choice(substrate_type_idxs, p=weights)\n",
    "    # incoming motif type selection\n",
    "    outtype = np.random.binomial(1, p=0.5)\n",
    "    # shared nodes number selection\n",
    "    shared_nodes = np.random.choice(\n",
    "        params.shared_nodes_probs.index, p=params.shared_nodes_probs.values\n",
    "    )\n",
    "    # results packing\n",
    "    Params = namedtuple(\n",
    "        \"Params\", \"substrate_motifs inner_motif_idx intype outtype shared_nodes\"\n",
    "    )\n",
    "    params = Params(\n",
    "        *[params.substrate_motifs, inner_motif_idx, intype, outtype, shared_nodes]\n",
    "    )\n",
    "    return params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now is the most tricky part. \n",
    "\n",
    "Selection an attachment pattern by the inner/outer motif types and the number of shared nodes fixed on the previous step. The approach strongly depends on the number of shared nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shared node case"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./pics/shared_node_pattern.png\" width=600 height=20/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After a thorough investigation we concluded the following list of patterns:\n",
    "\n",
    "(inner motif type / outer motif type / isoforms number)\n",
    "\n",
    "- TTT / TTT - 9 variants\n",
    "- TTT / TTG - 6 variants\n",
    "- TTG / TTT - 6 variants\n",
    "- TTG / TTG - 5 variants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_attachment_matrix_shared_node(substrate_matrix, params):\n",
    "    \"\"\"\n",
    "    Attachment patterns constructing for shared node case and random selection the particular one\n",
    "    ________________________________________________________________________\n",
    "    substrate_matrix - the netwotk we are growing\n",
    "    params - attachment parameters from previous stage of analysis (see get_attachment_params)\n",
    "    \"\"\"\n",
    "    inner_motif = f.split_motif(params.substrate_motifs[params.inner_motif_idx])\n",
    "    inner_motif_matrix = substrate_matrix[inner_motif, :][:, inner_motif]\n",
    "    outer_motif_matrix = f.build_motif_from_string(\"0 1 1 0 0 1 0 0 0\")\n",
    "    # check if there are target genes in the considered motifs\n",
    "    tg_in = inner_motif_matrix.sum(axis=0).argmin() if params.intype == 1 else None\n",
    "    tg_out = outer_motif_matrix.sum(axis=0).argmin() if params.outtype == 1 else None\n",
    "    patterns = [] # accumulator of appropriate pattern\n",
    "    for idx_in, role_out in product(*[range(3)]*2):\n",
    "        # filtering out inappropriate patterns (by target gene )\n",
    "        if (idx_in != tg_in) & (role_out == tg_out):\n",
    "            continue\n",
    "        if (idx_in == tg_in) & (role_out != tg_out):\n",
    "            continue\n",
    "        I = nx.DiGraph(inner_motif_matrix)\n",
    "        O = nx.DiGraph(outer_motif_matrix)\n",
    "        mapping = {i: i+3 for i in range(3)}\n",
    "        mapping[role_out] = idx_in\n",
    "        O = nx.relabel_nodes(O, mapping=mapping)\n",
    "        C = nx.compose(I, O)\n",
    "        compounded_matrix = nx.convert_matrix.to_numpy_array(C)\n",
    "        patterns.append(compounded_matrix)\n",
    "    attachment_matrix = patterns[np.random.randint(len(patterns))]\n",
    "    return attachment_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shared edge case"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./pics/shared_edge_pattern.png\" width=600 height=20/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results of isoforms diversity analysis:\n",
    "\n",
    "(inner motif type / outer motif type / isoforms number)\n",
    "\n",
    "- TTT / TTT - 9 variants\n",
    "- TTT / TTG - 3 variants\n",
    "- TTG / TTT - 3 variants\n",
    "- TTG / TTG - 5 variants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_outer_motif_matrix(role_edge):\n",
    "    \"\"\"\n",
    "    Selection of incoming motif matrix based on shared edge type\n",
    "    \"\"\"\n",
    "    if role_edge == (2, 1):\n",
    "        return f.build_motif_from_string(\"0 1 1 0 0 0 0 1 0\")\n",
    "    if role_edge == (2, 0):\n",
    "        return f.build_motif_from_string(\"0 1 0 0 0 0 1 1 0\")\n",
    "    if role_edge == (1, 0):\n",
    "        return f.build_motif_from_string(\"0 0 0 1 0 0 1 1 0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_attachment_matrix_shared_edge(substrate_matrix, params):\n",
    "    \"\"\"\n",
    "    Attachment patterns constructing for shared edge case and random selection the particular one\n",
    "    ________________________________________________________________________\n",
    "    substrate_matrix - the netwotk we are growing\n",
    "    params - attachment parameters from previous stage of analysis (see get_attachment_params)\n",
    "    \"\"\"\n",
    "    inner_motif = f.split_motif(params.substrate_motifs[params.inner_motif_idx])\n",
    "    inner_motif_matrix = substrate_matrix[inner_motif, :][:, inner_motif]\n",
    "    inner_nodes_roles = list(inner_motif_matrix.sum(axis=0).astype(int))\n",
    "    # check if there is a target gene\n",
    "    tg_in = inner_nodes_roles.index(0) if params.intype == 1 else None\n",
    "    # assignment roles and corresponding identifiers to the edges\n",
    "    role_edges = list(combinations(range(2, -1, -1), 2))\n",
    "    idx_by_role = lambda x: inner_nodes_roles.index(x)\n",
    "    idx_edges_in = [(idx_by_role(source), idx_by_role(target)) for source, target in role_edges]\n",
    "    patterns = []\n",
    "    for idx_edge_in, role_edge_out in product(idx_edges_in, role_edges):\n",
    "        outer_motif_matrix = get_outer_motif_matrix(role_edge_out)\n",
    "        outer_nodes_roles = list(outer_motif_matrix.sum(axis=0).astype(int))\n",
    "        # reveal positions by known edges roles\n",
    "        idx_by_role = lambda x: outer_nodes_roles.index(x)\n",
    "        idx_edge_out = tuple(idx_by_role(v) for v in role_edge_out)\n",
    "        # check if there is a target gene\n",
    "        tg_out = outer_motif_matrix.sum(axis=0).argmin() if params.outtype == 1 else None\n",
    "        # filtering out inappropriate patterns (by target gene )\n",
    "        if (idx_edge_in[0] != tg_in) & (idx_edge_out[0] == tg_out):\n",
    "            continue\n",
    "        if (idx_edge_in[0] == tg_in) & (idx_edge_out[0] != tg_out):\n",
    "            continue\n",
    "        if (idx_edge_in[1] != tg_in) & (idx_edge_out[1] == tg_out):\n",
    "            continue\n",
    "        if (idx_edge_in[1] == tg_in) & (idx_edge_out[1] != tg_out):\n",
    "            continue\n",
    "        I = nx.DiGraph(inner_motif_matrix)\n",
    "        O = nx.DiGraph(outer_motif_matrix)\n",
    "        mapping = {i: i+3 for i in range(3)}\n",
    "        mapping[1], mapping[2] = idx_edge_in\n",
    "        O = nx.relabel_nodes(O, mapping=mapping)\n",
    "        C = nx.compose(I, O)\n",
    "        compounded_matrix = nx.convert_matrix.to_numpy_array(C)\n",
    "        patterns.append(compounded_matrix)\n",
    "    attachment_matrix = patterns[np.random.randint(len(patterns))]\n",
    "    return attachment_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_substrate_matrix(substrate_matrix, attachment_matrix, inner_motif):\n",
    "    \"\"\"\n",
    "    Substrate network update by selected attachment pattern\n",
    "    ________________________________________________________________________\n",
    "    substrate_matrix - the netwotk we are growing\n",
    "    attachment_matrix - randomly selected attachment pattern compatible with chosen params\n",
    "    inner_motif - inner triad we attach to\n",
    "    \"\"\"\n",
    "    substrate_matrix_upd = deepcopy(substrate_matrix)\n",
    "    n_nodes_to_join = int(attachment_matrix.shape[0] - 3)\n",
    "    substrate_matrix_upd = np.concatenate(\n",
    "        (substrate_matrix_upd, np.zeros((n_nodes_to_join, substrate_matrix_upd.shape[1]))), axis=0\n",
    "    )\n",
    "    substrate_matrix_upd = np.concatenate(\n",
    "        (substrate_matrix_upd, np.zeros((substrate_matrix_upd.shape[0], n_nodes_to_join))), axis=1\n",
    "    )\n",
    "    shape = substrate_matrix_upd.shape[0]\n",
    "    # interaction matrix update\n",
    "    substrate_matrix_upd[\n",
    "        np.ix_(range(shape-n_nodes_to_join, shape), range(shape-n_nodes_to_join, shape))\n",
    "    ] = attachment_matrix[np.ix_(range(3, 3+n_nodes_to_join) ,range(3, 3+n_nodes_to_join))]\n",
    "    substrate_matrix_upd[\n",
    "        np.ix_(range(shape-n_nodes_to_join, shape), inner_motif)\n",
    "    ] = attachment_matrix[np.ix_(range(3, 3+n_nodes_to_join) ,range(3))]\n",
    "    substrate_matrix_upd[\n",
    "        np.ix_(inner_motif, range(shape-n_nodes_to_join, shape))\n",
    "    ] = attachment_matrix[np.ix_(range(3), range(3, 3+n_nodes_to_join))]\n",
    "    return substrate_matrix_upd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stack all in the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_artificial_network(\n",
    "    interaction_matrix, \n",
    "    motifs=None, \n",
    "    motifs_network=None, \n",
    "    nucleus_size=50,\n",
    "    network_size = 1000,\n",
    "    random_seed=cfg[\"RANDOM_SEED\"]\n",
    "):\n",
    "    \"\"\"\n",
    "    Aggragated pipeline of artificial network generation\n",
    "    ________________________________________________________________________\n",
    "    interaction_matrix (numpy.array) \n",
    "        Binary interaction matrix for genes\n",
    "    motifs (numpy.array, default=None) \n",
    "        List of unique identifiers for condidered motifs (FFL triads). \n",
    "        If None motif counting is launched\n",
    "    motifs_network (numpy.array, default=None) \n",
    "        Vertex-based motifs network (linkage by shared nodes)\n",
    "        If None VMN buiding algorithm is launched\n",
    "    nucleus_size (int, default=50)\n",
    "        Minimal required size of initial nucleus. \n",
    "        The resulting size may be slightly higher as we may attach two nodes per time.\n",
    "    network_size (int, default=1000)\n",
    "        Required resulting network size.\n",
    "        The resulting size may be slightly higher as we may attach two nodes per time.\n",
    "    random_seed (int, default=19)\n",
    "        Reproducibility parameter\n",
    "    \"\"\"\n",
    "    assert (motifs is None) & (motifs_network is None) | (motifs is not None)\n",
    "    np.random.seed(random_seed)\n",
    "    init_time = datetime.now()\n",
    "    \n",
    "    # check if motifs are provided and search them otherwise \n",
    "    if motifs is None:\n",
    "        print(\"Motifs are not provided. Motif search is in progress...\")\n",
    "        motifs_orig, counter_orig = f.motif_search(\n",
    "            cfg, interaction_matrix, batch_size=10000, verbose=False\n",
    "        )\n",
    "        motifs = motifs_orig[\"030T\"]\n",
    "        print()\n",
    "    \n",
    "    # check if motifs are provided and search them otherwise \n",
    "    if motifs_network is None:\n",
    "        print(\"Vertex-based FFL net is not provided. VMN building is in progress...\")\n",
    "        motifs_network = f.build_vmn(motifs, verbose=False)\n",
    "        print()\n",
    "    \n",
    "    # nucleus subsampling\n",
    "    substrate_matrix = get_network_nucleus(\n",
    "        interaction_matrix, motifs, motifs_network, min_size=nucleus_size\n",
    "    )\n",
    "    print(f\"Nucleus matrix shape: {substrate_matrix.shape}\")\n",
    "    sleep(2)\n",
    "    # preferencial attachment start\n",
    "    substrate_size = substrate_matrix.shape[0]\n",
    "    pbar = tqdm(initial=substrate_size, total=network_size)\n",
    "    while substrate_size < network_size:\n",
    "        network_params = get_network_params(substrate_matrix)\n",
    "        params = get_attachment_params(network_params)\n",
    "        if params.shared_nodes == 1:\n",
    "            attachment_matrix = get_attachment_matrix_shared_node(substrate_matrix, params)\n",
    "        else:\n",
    "            attachment_matrix = get_attachment_matrix_shared_edge(substrate_matrix, params)\n",
    "        inner_motif = f.split_motif(params.substrate_motifs[params.inner_motif_idx])\n",
    "        substrate_matrix = update_substrate_matrix(substrate_matrix, attachment_matrix, inner_motif)\n",
    "        substrate_size = substrate_matrix.shape[0]\n",
    "        n_nodes_to_join = int(attachment_matrix.shape[0] - 3)\n",
    "        pbar.update(n_nodes_to_join)\n",
    "    pbar.close()\n",
    "    sleep(2)\n",
    "    print()\n",
    "    print(f\"Network has been successfully generated!\\nTotal time spent: {datetime.now() - init_time}\")\n",
    "    return substrate_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test launch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nucleus matrix shape: (50, 50)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1001it [11:32,  1.37it/s]                         \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Network has been successfully generated!\n",
      "Total time spent: 0:11:37.649501\n"
     ]
    }
   ],
   "source": [
    "artificial_matrix = generate_artificial_network(\n",
    "    interaction_matrix, motifs=motifs, motifs_network=motifs_network,\n",
    "    nucleus_size=50, network_size=1000\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1001, 1001)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "artificial_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 120 ms, sys: 62.2 ms, total: 182 ms\n",
      "Wall time: 1.74 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'021C': 30202, '021D': 25661, '021U': 9004, '030C': 0, '030T': 533}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "motifs_art, counter_art = f.motif_search(cfg, artificial_matrix, batch_size=10000)\n",
    "counter_art"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
